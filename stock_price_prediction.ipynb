{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOaR1MSwr0eJF2Io3J24/rF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jodog0412/STOCK-PRICE-PREDICTION/blob/main/stock_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preprocessing"
      ],
      "metadata": {
        "id": "KFLdKrGRNN2m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aehZSW46c595"
      },
      "outputs": [],
      "source": [
        "!pip install yfinance\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=yf.Ticker(\"XOM\").history(period=\"2y\")\n",
        "data=data['Close']\n",
        "plt.plot(data)"
      ],
      "metadata": {
        "id": "vrzONvljdBh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "data=scaler.fit_transform(data.to_numpy().reshape(-1,1)).flatten()"
      ],
      "metadata": {
        "id": "_59_r4yAdElb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iw = 128\n",
        "ow = 128\n",
        "train=data[:-iw]"
      ],
      "metadata": {
        "id": "rvsOtifWePZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data_size: {data.shape} train_size: {train.shape}\")"
      ],
      "metadata": {
        "id": "2f5x1-RtGKRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class windowDataset(Dataset):\n",
        "    def __init__(self, y, input_window=80, output_window=20, stride=5):\n",
        "        #총 데이터의 개수\n",
        "        L = y.shape[0]\n",
        "        #stride씩 움직일 때 생기는 총 sample의 개수\n",
        "        num_samples = (L - input_window - output_window) // stride + 1\n",
        "\n",
        "        #input과 output\n",
        "        X = np.zeros([input_window, num_samples])\n",
        "        Y = np.zeros([output_window, num_samples])\n",
        "\n",
        "        for i in np.arange(num_samples):\n",
        "            start_x = stride*i\n",
        "            end_x = start_x + input_window\n",
        "            X[:,i] = y[start_x:end_x]\n",
        "\n",
        "            start_y = stride*i + input_window\n",
        "            end_y = start_y + output_window\n",
        "            Y[:,i] = y[start_y:end_y]\n",
        "\n",
        "        # size: [num_samples, input_window, 1]\n",
        "        X = X.reshape(X.shape[1], X.shape[0], 1) \n",
        "        Y = Y.reshape(Y.shape[1], Y.shape[0], 1)\n",
        "        self.x = X\n",
        "        self.y = Y\n",
        "        self.len = len(X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.x[i], self.y[i]\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "MlTU5S0teYiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = windowDataset(train, input_window=iw, output_window=ow, stride=1)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)"
      ],
      "metadata": {
        "id": "JTQmCWbJedgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Model"
      ],
      "metadata": {
        "id": "n6AdP_DiQAmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Transformer\n",
        "import math"
      ],
      "metadata": {
        "id": "1cXbmHtb8bs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Transformer"
      ],
      "metadata": {
        "id": "vgkfYcgfQLQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TF_config():\n",
        "    def __init__(self):\n",
        "        self.d_model=512\n",
        "        self.nhead=8\n",
        "        self.nlayers=4\n",
        "        self.dropout=0.1\n",
        "\n",
        "class TFModel(nn.Module):\n",
        "    def __init__(self,configs, iw=iw, ow=ow):\n",
        "        super(TFModel, self).__init__()\n",
        "        d_model=configs.d_model\n",
        "        nhead=configs.nhead\n",
        "        dropout=configs.dropout\n",
        "        nlayers=configs.nlayers\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=nlayers) \n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(1, d_model//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_model//2, d_model)\n",
        "        )\n",
        "        \n",
        "        self.linear =  nn.Sequential(\n",
        "            nn.Linear(d_model, d_model//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_model//2, 1)\n",
        "        )\n",
        "\n",
        "        self.linear2 = nn.Sequential(\n",
        "            nn.Linear(iw, (iw+ow)//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear((iw+ow)//2, ow)\n",
        "        ) \n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, srcmask):\n",
        "        src = self.encoder(src)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src.transpose(0,1), srcmask).transpose(0,1)\n",
        "        output = self.linear(output)[:,:,0]\n",
        "        output = self.linear2(output)\n",
        "        return output\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "    def gen_attention_mask(x):\n",
        "        mask = torch.eq(x, 0)\n",
        "        return mask"
      ],
      "metadata": {
        "id": "GPqOG4Gv8ZTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) DLinear"
      ],
      "metadata": {
        "id": "7N1RoygmQOeC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DL_config():\n",
        "    def __init__(self):\n",
        "        self.seq_len=iw\n",
        "        self.pred_len=ow\n",
        "        self.individual=0\n",
        "        self.enc_in=4\n",
        "        \n",
        "class moving_avg(nn.Module):\n",
        "    \"\"\"\n",
        "    Moving average block to highlight the trend of time series\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size, stride):\n",
        "        super(moving_avg, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # padding on the both ends of time series\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "        x = self.avg(x.permute(0, 2, 1))\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "class series_decomp(nn.Module):\n",
        "    \"\"\"\n",
        "    Series decomposition block\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size):\n",
        "        super(series_decomp, self).__init__()\n",
        "        self.moving_avg = moving_avg(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        moving_mean = self.moving_avg(x)\n",
        "        res = x - moving_mean\n",
        "        return res, moving_mean\n",
        "\n",
        "class DLinear(nn.Module):\n",
        "    \"\"\"\n",
        "    Decomposition-Linear\n",
        "    \"\"\"\n",
        "    def __init__(self, configs):\n",
        "        super(DLinear, self).__init__()\n",
        "        self.seq_len = configs.seq_len\n",
        "        self.pred_len = configs.pred_len\n",
        "\n",
        "        # Decompsition Kernel Size\n",
        "        kernel_size = 25\n",
        "        self.decompsition = series_decomp(kernel_size)\n",
        "        self.individual = configs.individual\n",
        "        self.channels = configs.enc_in\n",
        "\n",
        "        if self.individual: #individual=1\n",
        "            self.Linear_Seasonal = nn.ModuleList()\n",
        "            self.Linear_Trend = nn.ModuleList()\n",
        "            \n",
        "            for i in range(self.channels):\n",
        "                self.Linear_Seasonal.append(nn.Linear(self.seq_len,self.pred_len))\n",
        "                self.Linear_Trend.append(nn.Linear(self.seq_len,self.pred_len))\n",
        "\n",
        "                # Use this two lines if you want to visualize the weights\n",
        "                # self.Linear_Seasonal[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "                # self.Linear_Trend[i].weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "        else: #individual=0\n",
        "            self.Linear_Seasonal = nn.Linear(self.seq_len,self.pred_len)\n",
        "            self.Linear_Trend = nn.Linear(self.seq_len,self.pred_len)\n",
        "            \n",
        "            # Use this two lines if you want to visualize the weights\n",
        "            # self.Linear_Seasonal.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "            # self.Linear_Trend.weight = nn.Parameter((1/self.seq_len)*torch.ones([self.pred_len,self.seq_len]))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [Batch, Input length, Channel]\n",
        "        seasonal_init, trend_init = self.decompsition(x)\n",
        "        seasonal_init, trend_init = seasonal_init.permute(0,2,1), trend_init.permute(0,2,1)\n",
        "        if self.individual: #individual=1\n",
        "            seasonal_output = torch.zeros([seasonal_init.size(0),seasonal_init.size(1),self.pred_len],dtype=seasonal_init.dtype).to(seasonal_init.device)\n",
        "            trend_output = torch.zeros([trend_init.size(0),trend_init.size(1),self.pred_len],dtype=trend_init.dtype).to(trend_init.device)\n",
        "            for i in range(self.channels):\n",
        "                seasonal_output[:,i,:] = self.Linear_Seasonal[i](seasonal_init[:,i,:])\n",
        "                trend_output[:,i,:] = self.Linear_Trend[i](trend_init[:,i,:])\n",
        "        else: #individual=0\n",
        "            seasonal_output = self.Linear_Seasonal(seasonal_init)\n",
        "            trend_output = self.Linear_Trend(trend_init)\n",
        "\n",
        "        x = seasonal_output + trend_output\n",
        "        return x.permute(0,2,1) # to [Batch, Output length, Channel]"
      ],
      "metadata": {
        "id": "7LItj8WFdbcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Train"
      ],
      "metadata": {
        "id": "oowWqT8cQVCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\")\n",
        "lr = 1e-4\n",
        "criterion = nn.MSELoss()\n",
        "class modelParam():\n",
        "    def __init__(self,label):\n",
        "        if label=='TF': self.model=TFModel(configs=TF_config()).to(device)\n",
        "        else: self.model=DLinear(configs=DL_config()).to(device)\n",
        "        self.optimizer=torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "    def epoch(self,epoch):\n",
        "        self.epoch=epoch\n",
        "        return self.epoch"
      ],
      "metadata": {
        "id": "36y2BsM0jTtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TF=modelParam('TF')\n",
        "model=TF.model.to(device)\n",
        "optimizer=TF.optimizer\n",
        "epoch=TF.epoch(70)\n",
        "progress = tqdm(range(epoch))\n",
        "model.train()\n",
        "\n",
        "losses=[]\n",
        "for i in progress:\n",
        "    batchloss = 0.0\n",
        "    for (inputs, outputs) in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.generate_square_subsequent_mask(inputs.shape[1]).to(device)\n",
        "        result = model(inputs.float().to(device),  src_mask)\n",
        "        loss = criterion(result, outputs[:,:,0].float().to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batchloss += loss\n",
        "    losses.append(batchloss.cpu().item())\n",
        "    progress.set_description(\"loss: {:0.6f}\".format(batchloss.cpu().item() / len(train_loader)))"
      ],
      "metadata": {
        "id": "tVktvdRf-Mbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "ycdpMMC6-j6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DL=modelParam('DL')\n",
        "model=DL.model.to(device)\n",
        "optimizer=DL.optimizer\n",
        "epoch=DL.epoch(140)\n",
        "progress = tqdm(range(epoch))\n",
        "model.train()\n",
        "losses=[]\n",
        "for i in progress:\n",
        "    batchloss = 0.0\n",
        "    for (inputs, outputs) in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        result = model(inputs.float().to(device))\n",
        "        loss = criterion(result, outputs.float().to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        batchloss += loss\n",
        "    losses.append(batchloss.cpu().item())\n",
        "    progress.set_description(\"loss: {:0.6f}\".format(batchloss.cpu().item() / len(train_loader)))"
      ],
      "metadata": {
        "id": "oltHHFjBiwKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "di0-6BqUizmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(label):\n",
        "    input = torch.tensor(train[-iw:]).reshape(1,-1,1).to(device).float().to(device)\n",
        "    if label=='TF':\n",
        "        model=TF.model.to(device)\n",
        "        src_mask = model.generate_square_subsequent_mask(input.shape[1]).to(device)\n",
        "        model.eval()\n",
        "        predictions = model(input, src_mask)\n",
        "        return predictions.detach().cpu().numpy()\n",
        "    else:\n",
        "        model=DL.model.to(device)\n",
        "        input = torch.tensor(train[-iw:]).reshape(1,-1,1).to(device).float().to(device)\n",
        "        model.eval()\n",
        "        predictions = model(input)\n",
        "        return predictions.detach().cpu().numpy().reshape(1,-1)"
      ],
      "metadata": {
        "id": "rK2isok9-w-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real = data\n",
        "real = scaler.inverse_transform(real.reshape(-1,1))[:,0]\n",
        "TF_pred = evaluate('TF')\n",
        "TF_pred = scaler.inverse_transform(TF_pred)[0]\n",
        "DL_pred = evaluate('DL')\n",
        "DL_pred = scaler.inverse_transform(DL_pred)[0]\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot(range(300,len(data)),real[300:,],label=\"real\")\n",
        "plt.plot(range(len(data)-ow,len(data)),TF_pred,label=\"TF_predict\")\n",
        "plt.plot(range(len(data)-ow,len(data)),DL_pred,label=\"DL_predict\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oF_em7a7j1pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oX4qfpwtj7Ga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}